"""
Memory Extraction è°ƒè¯•å·¥å…·

è¿™ä¸æ˜¯ä¸€ä¸ªä¼ ç»Ÿçš„å•å…ƒæµ‹è¯•ï¼Œè€Œæ˜¯ä¸€ä¸ªå¸®åŠ©è°ƒè¯•å’Œä¼˜åŒ– Prompt çš„å¯è§†åŒ–å·¥å…·ã€‚
è¿è¡Œæ­¤è„šæœ¬åï¼Œæ‚¨å°†åœ¨ç»ˆç«¯çœ‹åˆ°ï¼š
1. å‘é€ç»™å¤§æ¨¡å‹çš„å®Œæ•´ Promptï¼ˆåŒ…å« System Promptã€Few-shot å’Œå½“å‰å¯¹è¯ï¼‰
2. å¤§æ¨¡å‹çš„åŸå§‹è¿”å›ç»“æœ
3. æœ€ç»ˆæå–å‡ºæ¥çš„ Profile å’Œ Event

æ‚¨å¯ä»¥æ ¹æ®è¾“å‡ºç»“æœï¼Œæ‰‹åŠ¨è°ƒæ•´ Prompt æ–‡ä»¶ï¼Œç„¶åå†æ¬¡è¿è¡Œæµ‹è¯•ï¼Œå½¢æˆè¿­ä»£ä¼˜åŒ–å¾ªç¯ã€‚

Usage:
    cd server
    venv\\Scripts\\python tests/test_memory_extraction_complex.py
    
    # æˆ–è€…è¿è¡Œå•ä¸ªåœºæ™¯
    venv\\Scripts\\python tests/test_memory_extraction_complex.py scenario5_long_work
"""
import os
import sys
import asyncio
import logging
import json
import uuid
import json
from pathlib import Path
from datetime import datetime

# ==============================================================================
# ç¯å¢ƒåˆå§‹åŒ–ï¼šç¡®ä¿èƒ½å¯¼å…¥ app æ¨¡å—
# ==============================================================================
SERVER_DIR = Path(__file__).resolve().parents[1]
if str(SERVER_DIR) not in sys.path:
    sys.path.insert(0, str(SERVER_DIR))

from app.core.config import settings
from app.services.memo import initialize_memo_sdk, MemoService
from app.vendor.memobase_server.models.blob import OpenAICompatibleMessage
from app.vendor.memobase_server.controllers.buffer import flush_buffer
from app.vendor.memobase_server.models.blob import BlobType
from app.vendor.memobase_server.env import CONFIG
from app.vendor.memobase_server.connectors import create_tables
from app.vendor.memobase_server.controllers.project import update_project_profile_config
from app.vendor.memobase_server.prompts.profile_init_utils import UserProfileTopic
from app.vendor.memobase_server.env import ProfileConfig

# ==============================================================================
# æ—¥å¿—é…ç½®ï¼šå¼€å¯è®°å¿†ç³»ç»Ÿçš„åº•å±‚æ—¥å¿—ï¼Œæ˜¾ç¤ºå‘é€ç»™å¤§æ¨¡å‹çš„ Prompt å’Œè¿”å›ç»“æœ
# ==============================================================================
def setup_test_logging():
    # è·å–åº•å±‚ prompt è¿½è¸ªè®°å½•å™¨
    prompt_logger = logging.getLogger("prompt_trace")
    prompt_logger.setLevel(logging.INFO)
    
    # è·å– Memobase ç³»ç»Ÿè®°å½•å™¨
    mb_logger = logging.getLogger("memobase_server")
    mb_logger.setLevel(logging.INFO)
    
    # ç»Ÿä¸€è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡ºï¼Œæ–¹ä¾¿åœ¨æµ‹è¯•ä¸­æŸ¥çœ‹
    handler = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s: %(message)s')
    handler.setFormatter(formatter)
    
    prompt_logger.addHandler(handler)
    mb_logger.addHandler(handler)
    
    # ç¦ç”¨å¯èƒ½å­˜åœ¨çš„å…¶ä»–å¤„ç†å™¨ï¼Œé¿å…é‡å¤æ‰“å°
    prompt_logger.propagate = False
    mb_logger.propagate = False

    # çŒ´å­è¡¥ä¸ï¼šç›‘æ§ llm_complete ä»¥ä¾¿æ‰“å°è¿”å›å€¼
    from app.vendor.memobase_server import llms
    original_llm_complete = llms.llm_complete
    
    async def patched_llm_complete(*args, **kwargs):
        result = await original_llm_complete(*args, **kwargs)
        if result.ok():
            data_to_log = result.data()
            if isinstance(data_to_log, dict):
                data_to_log = json.dumps(data_to_log, ensure_ascii=False, indent=2)
            
            # è·å–æœ¬æ¬¡è°ƒç”¨çš„ Prompt (ä¸ºäº†è°ƒè¯•æ–¹ä¾¿ï¼Œåªæ‰“å°æœ€å User éƒ¨åˆ†ï¼Œé˜²æ­¢ System Prompt åˆ·å±)
            user_prompt = kwargs.get('prompt', 'N/A')
            if len(str(user_prompt)) > 500:
                user_prompt = str(user_prompt)[:500] + "...(truncated)"
                
            separator = "#" * 80
            print(f"\n{separator}", flush=True)
            print(f"ğŸ§ [DEBUG VIEW] LLM RAW INTERACTION ({kwargs.get('prompt_id', 'unknown')})", flush=True)
            print(f"{separator}", flush=True)
            print(f"ğŸ‘‰ INPUT PROMPT (Snippet):\n{user_prompt}\n", flush=True)
            print(f"ğŸ‘ˆ RAW MODEL OUTPUT:\n{data_to_log}", flush=True)
            print(f"{separator}\n", flush=True)
            
            # ä¾ç„¶ä¿ç•™åŸæœ‰æ—¥å¿—è®°å½•ï¼Œä»¥é˜²ä¸‡ä¸€
            prompt_logger.info(f"--- LLM RESPONSE ---\n{data_to_log}\n--------------------")
        else:
            print(f"\nâŒ [LLM ERROR]: {result.msg()}\n")
            prompt_logger.error(f"--- LLM ERROR ---\n{result.msg()}\n-----------------")
        return result
    
    llms.llm_complete = patched_llm_complete

setup_test_logging()

# ==============================================================================
# æµ‹è¯•æ•°æ®åŠ è½½å‡½æ•°
# ==============================================================================
def load_scenario(name: str) -> list[OpenAICompatibleMessage]:
    """ä» txt æ–‡ä»¶åŠ è½½å¯¹è¯æ•°æ®"""
    path = SERVER_DIR / "tests" / "data" / "memory_test" / f"{name}.txt"
    messages = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line: continue
            
            # å¤„ç†å¸¦æ—¶é—´çš„æ ¼å¼: [2026/01/15 10:00] user: message
            time_prefix = ""
            if line.startswith("["):
                end_bracket = line.find("]")
                if end_bracket != -1:
                    time_prefix = line[:end_bracket+1] + " "
                    line = line[end_bracket+1:].strip()
            
            if line.lower().startswith("user:"):
                content = line[5:].strip()
                messages.append(OpenAICompatibleMessage(role="user", content=time_prefix + content))
            elif line.lower().startswith("assistant:"):
                content = line[10:].strip()
                messages.append(OpenAICompatibleMessage(role="assistant", content=time_prefix + content))
    return messages

def list_scenarios() -> list[str]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æµ‹è¯•åœºæ™¯"""
    path = SERVER_DIR / "tests" / "data" / "memory_test"
    path = SERVER_DIR / "tests" / "data" / "memory_test"
    return [f.stem for f in path.glob("*.txt")]

async def initialize_test_profiles(space_id: str):
    """æ³¨å…¥æµ‹è¯•ç”¨çš„ Profile ç»“æ„ï¼ˆæ›´ç¬¦åˆç¤¾äº¤åœºæ™¯ï¼‰"""
    print(f"\n[Setup] ğŸ”§ Injecting custom profile topics for space: {space_id}...")
    
    custom_profiles = [
        UserProfileTopic(
            "åŸºæœ¬ä¿¡æ¯",
            sub_topics=["å§“å", "å¹´é¾„", "æ€§åˆ«", "æ‰€åœ¨åœ°", "å®¶ä¹¡", "è¯­è¨€"]
        ),
        UserProfileTopic(
            "èŒä¸šä¸æ•™è‚²",
            sub_topics=["èŒä¸š", "å…¬å¸", "å­¦æ ¡", "ä¸“ä¸š", "å·¥ä½œçŠ¶æ€", "èŒä¸šç›®æ ‡"]
        ),
        UserProfileTopic(
            "å…´è¶£çˆ±å¥½",
            sub_topics=["è¿åŠ¨", "éŸ³ä¹", "ç”µå½±", "é˜…è¯»", "æ¸¸æˆ", "æ—…æ¸¸", "ç¾é£Ÿ"]
        ),
        UserProfileTopic(
            "ç”Ÿæ´»ä¹ æƒ¯",
            sub_topics=["ä½œæ¯", "é¥®é£Ÿåå¥½", "æ¶ˆè´¹ä¹ æƒ¯", "å±…ä½ç¯å¢ƒ"]
        ),
        UserProfileTopic(
            "æ€§æ ¼ä¸æƒ…æ„Ÿ",
            sub_topics=["æ€§æ ¼ç‰¹ç‚¹", "å½“å‰å¿ƒæƒ…", "å‹åŠ›æº", "æƒ…æ„ŸçŠ¶æ€"]
        ),
        UserProfileTopic(
            "äººé™…å…³ç³»",
            sub_topics=["å®¶äºº", "ä¼´ä¾£", "æœ‹å‹", "åŒäº‹", "å® ç‰©"]
        ),
        UserProfileTopic(
            "é‡è¦ç»å†",
            sub_topics=["è¿‡å»", "è¿‘æœŸè®¡åˆ’", "é•¿è¿œç›®æ ‡"]
        )
    ]
    
    # æ‰‹åŠ¨å°† UserProfileTopic å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼Œç¡®ä¿ sub_topics æ­£ç¡®åºåˆ—åŒ–
    # é¿å… direct json.dumps å¤±è´¥
    overwrite_config = []
    for p in custom_profiles:
        p_dict = {
            "topic": p.topic,
            "description": p.description,
            "sub_topics": []
        }
        for st in p.sub_topics:
            # st æ˜¯ SubTopic Pydantic Model æˆ–è€…å­—å…¸
            if hasattr(st, "model_dump"):
                p_dict["sub_topics"].append(st.model_dump(exclude_none=True))
            elif hasattr(st, "__dict__"):
                p_dict["sub_topics"].append(st.__dict__)
            else:
                 p_dict["sub_topics"].append(st)
        overwrite_config.append(p_dict)

    # æ„é€  ProfileConfig å¯¹è±¡å¹¶åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²
    config = ProfileConfig(overwrite_user_profiles=overwrite_config)
    config_str = json.dumps(config.__dict__, default=lambda o: o.__dict__)

    await update_project_profile_config(
        space_id, 
        profile_config=config_str
    )
    print("[Setup] âœ… Custom profiles injected.")

# ==============================================================================
# æ ¸å¿ƒæ‰§è¡Œå‡½æ•°
# ==============================================================================
async def run_extraction_cycle(user_id: str, space_id: str, scenario_name: str):
    """
    æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„æå–å‘¨æœŸï¼šè½½å…¥æ•°æ® -> æ’å…¥ -> æ‰‹åŠ¨è§¦å‘æå– -> æ‰“å°ç»“æœ
    
    è¿™ä¸ªå‡½æ•°ä¸åšä»»ä½•æ–­è¨€ï¼Œåªæ‰“å°ç»“æœä¾›äººå·¥åˆ¤æ–­ã€‚
    """
    print("\n" + "="*80)
    print(f">>> SCENARIO: {scenario_name}")
    print("="*80)
    
    messages = load_scenario(scenario_name)
    print(f"\n[Step 0] Loaded {len(messages)} messages from {scenario_name}.txt")
    print("-" * 40)
    for i, msg in enumerate(messages):
        role_display = "ğŸ‘¤ USER" if msg.role == "user" else "ğŸ¤– ASSISTANT"
        print(f"  {i+1:02d}. {role_display}: {msg.content[:60]}{'...' if len(msg.content) > 60 else ''}")
    print("-" * 40)
    
    # 1. æ’å…¥å¯¹è¯åˆ°ç¼“å†²åŒº
    await MemoService.ensure_user(user_id, space_id)
    await MemoService.insert_chat(user_id, space_id, messages)
    print(f"\n[Step 1] âœ… Inserted {len(messages)} messages to buffer.")
    
    # 2. æ‰‹åŠ¨è§¦å‘ç¼“å†²åŒºåˆ·æ–°ï¼ˆæå–è®°å¿†ï¼‰
    print(f"\n[Step 2] ğŸ”„ Triggering buffer flush (LLM processing)...")
    print("         (Watch for 'memobase_llm_prompt' logs below)")
    print("-" * 40)
    
    p = await flush_buffer(user_id, space_id, BlobType.chat)
    
    print("-" * 40)
    if not p.ok():
        print(f"\n[Error] âŒ Flush failed: {p.msg()}")
        return
    print(f"\n[Step 3] âœ… LLM Processing Complete.")
    
    # 3. è·å–æå–å‡ºæ¥çš„ Profile å’Œ Events
    profiles = await MemoService.get_user_profiles(user_id, space_id)
    events = await MemoService.get_recent_memories(user_id, space_id, topk=50)
    
    # 4. æ‰“å° Profile ç»“æœ
    print("\n" + "="*80)
    print("ğŸ“‹ EXTRACTED PROFILES (User Attributes)")
    print("="*80)
    if profiles.profiles:
        for i, p in enumerate(profiles.profiles):
            topic = p.attributes.get('topic', 'N/A')
            sub_topic = p.attributes.get('sub_topic', 'N/A')
            print(f"  {i+1:02d}. [{topic}/{sub_topic}]")
            print(f"      Content: {p.content}")
            print(f"      Updated: {p.updated_at}")
            print()
    else:
        print("  (No profiles extracted)")
    
    # 5. æ‰“å° Event ç»“æœ
    print("\n" + "="*80)
    print("ğŸ“… EXTRACTED EVENTS (User Activities/Facts)")
    print("="*80)
    if events.gists:
        for i, g in enumerate(events.gists):
            gist_data = g.gist_data if isinstance(g.gist_data, dict) else g.gist_data.model_dump()
            summary = gist_data.get('summary', gist_data.get('content', 'N/A'))
            print(f"  {i+1:02d}. {summary}")
            print(f"      Created: {g.created_at}")
            print()
    else:
        print("  (No events extracted)")
    
    print("\n" + "="*80)
    print(f">>> END OF SCENARIO: {scenario_name}")
    print("="*80 + "\n")
    
    return profiles, events


async def main():
    """ä¸»å…¥å£å‡½æ•°"""
    sys.stdout.reconfigure(encoding='utf-8')

    # ==========================================================================
    # é…ç½®æµ‹è¯•ç¯å¢ƒçš„ LLM (åŸºäºç”¨æˆ·æ¯æä¾›çš„ GLM-4.7 é…ç½®)
    # ==========================================================================
    settings.MEMOBASE_LLM_API_KEY = "4dce12de026450fe6d485bdff7847cde.pVqEddmkBZjdBSs6"
    settings.MEMOBASE_LLM_BASE_URL = "https://api.z.ai/api/coding/paas/v4"
    settings.MEMOBASE_BEST_LLM_MODEL = "glm-4.7"
    
    # åŒæ—¶ä¹Ÿè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿åº•å±‚åº“èƒ½è¯»åˆ°
    os.environ["MEMOBASE_LLM_API_KEY"] = settings.MEMOBASE_LLM_API_KEY
    os.environ["MEMOBASE_LLM_BASE_URL"] = settings.MEMOBASE_LLM_BASE_URL
    os.environ["MEMOBASE_BEST_LLM_MODEL"] = settings.MEMOBASE_BEST_LLM_MODEL

    # æ£€æŸ¥ API KEY
    if not settings.MEMOBASE_LLM_API_KEY:
        print("âŒ ERROR: MEMOBASE_LLM_API_KEY not set in environment.")
        print("Please set it in .env or as environment variable.")
        sys.exit(1)
    
    # åˆå§‹åŒ– SDK
    print("\nğŸš€ Initializing Memobase SDK with real LLM...")
    await initialize_memo_sdk()
    create_tables()
    print("âœ… SDK Initialized.\n")
    
    # ç¡®å®šè¦è¿è¡Œçš„åœºæ™¯
    available_scenarios = list_scenarios()
    print(f"ğŸ“‚ Available scenarios: {', '.join(available_scenarios)}")
    
    # å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šåœºæ™¯
    if len(sys.argv) > 1:
        selected = [s for s in sys.argv[1:] if s in available_scenarios]
        if not selected:
            print(f"âŒ No valid scenarios specified. Available: {available_scenarios}")
            sys.exit(1)
    else:
        # é»˜è®¤è¿è¡Œæ‰€æœ‰åœºæ™¯
        selected = available_scenarios
    
    print(f"ğŸ¯ Running scenarios: {', '.join(selected)}\n", flush=True)
    
    # ä½¿ç”¨å”¯ä¸€çš„ user_id é¿å…æ±¡æŸ“
    user_id = str(uuid.uuid4())
    space_id = "__root__"
    
    print(f"ğŸ‘¤ Test User ID: {user_id}", flush=True)
    print(f"ğŸ  Test Space ID: {space_id}", flush=True)
    
    # æ³¨å…¥è‡ªå®šä¹‰ Profile ç»“æ„
    await initialize_test_profiles(space_id)
    
    # ä¾æ¬¡è¿è¡Œæ¯ä¸ªåœºæ™¯
    for scenario in sorted(selected):
        print(f"DEBUG: Entering loop for {scenario}", flush=True)
        try:
            await run_extraction_cycle(user_id, space_id, scenario)
        except Exception as e:
            print(f"\nâŒ Error in scenario {scenario}: {e}", flush=True)
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*80, flush=True)
    print("ğŸ ALL SCENARIOS COMPLETE", flush=True)
    print("="*80, flush=True)
    print("\nNow you can review the results above and adjust your prompts in:", flush=True)
    print("  - server/app/vendor/memobase_server/prompts/zh_summary_entry_chats.py", flush=True)
    print("  - server/app/vendor/memobase_server/prompts/zh_extract_profile.py", flush=True)
    print("  - server/app/vendor/memobase_server/prompts/event_tagging.py", flush=True)
    print("\nThen run this script again to see the effect of your changes.", flush=True)

if __name__ == "__main__":
    asyncio.run(main())
